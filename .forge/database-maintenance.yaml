goal: "Perform comprehensive database maintenance including backups, optimization, and health checks"
generate_pr: true

triggers:
  - display_name: "Database Maintenance Schedule"
    description: "Scheduled database maintenance tasks"
    provider: "cron"
    config:
      schedule: "0 2 * * SUN"  # Weekly on Sunday at 2 AM
      timezone: "UTC"
    labels:
      priority: "medium"
      team: "database-ops"

steps:
  - name: "Pre-Maintenance Validation"
    type: "action"
    description: "Validate database health and readiness for maintenance"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== DATABASE PRE-MAINTENANCE VALIDATION ==="
        
        MAINTENANCE_ID="DB-MAINT-$(date +%Y%m%d%H%M%S)"
        echo "Maintenance ID: $MAINTENANCE_ID"
        
        # Check database connectivity across all clouds
        echo "Checking database connectivity..."
        
        # AWS RDS instances
        aws rds describe-db-instances --query 'DBInstances[?DBInstanceStatus==`available`].[DBInstanceIdentifier,Engine,DBInstanceStatus]' --output table
        
        # GCP Cloud SQL instances  
        gcloud sql instances list --filter="state:RUNNABLE" --format="table(name,databaseVersion,state)"
        
        # Azure SQL databases
        az sql db list --resource-group prod-rg --server prod-sql-server --query '[].{Name:name,Status:status}' --output table
        
        # Check replication status
        echo "Checking replication status..."
        
        # AWS RDS read replicas
        aws rds describe-db-instances --query 'DBInstances[?ReadReplicaSourceDBInstanceIdentifier!=null].[DBInstanceIdentifier,ReadReplicaSourceDBInstanceIdentifier]' --output table
        
        # Test database connections
        echo "Testing database connections..."
        
        # PostgreSQL connection test
        PGPASSWORD="$(vault kv get -field=password secret/database/postgres)" psql -h prod-postgres.aws.company.internal -U admin -d company -c "SELECT version();" || {
          echo "‚ùå PostgreSQL connection failed"
          exit 1
        }
        
        # MySQL connection test  
        mysql -h prod-mysql.gcp.company.internal -u admin -p"$(vault kv get -field=password secret/database/mysql)" -e "SELECT VERSION();" || {
          echo "‚ùå MySQL connection failed"
          exit 1
        }
        
        # Check disk space
        echo "Checking database disk usage..."
        
        # AWS RDS storage
        aws rds describe-db-instances --query 'DBInstances[*].[DBInstanceIdentifier,AllocatedStorage,StorageEncrypted]' --output table
        
        # Check for long-running queries
        echo "Checking for long-running queries..."
        
        PGPASSWORD="$(vault kv get -field=password secret/database/postgres)" psql -h prod-postgres.aws.company.internal -U admin -d company -c "
        SELECT pid, now() - pg_stat_activity.query_start AS duration, query 
        FROM pg_stat_activity 
        WHERE (now() - pg_stat_activity.query_start) > interval '5 minutes';"
        
        echo "‚úÖ Pre-maintenance validation complete"
      parameters:
        timeout_minutes: 10

  - name: "Database Backup"
    type: "action"
    description: "Create comprehensive database backups"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== DATABASE BACKUP ==="
        
        BACKUP_DATE=$(date +%Y%m%d_%H%M%S)
        
        # Create RDS snapshots
        echo "Creating RDS snapshots..."
        
        aws rds describe-db-instances --query 'DBInstances[*].DBInstanceIdentifier' --output text | while read -r db_instance; do
          echo "Creating snapshot for $db_instance"
          
          aws rds create-db-snapshot \
            --db-snapshot-identifier "${db_instance}-maintenance-${BACKUP_DATE}" \
            --db-instance-identifier "$db_instance" || {
            echo "‚ùå Failed to create snapshot for $db_instance"
            exit 1
          }
        done
        
        # Wait for snapshots to complete
        echo "Waiting for RDS snapshots to complete..."
        
        aws rds describe-db-snapshots \
          --snapshot-type manual \
          --query "DBSnapshots[?contains(DBSnapshotIdentifier, '${BACKUP_DATE}')].[DBSnapshotIdentifier,Status]" \
          --output table
        
        # Monitor snapshot progress
        while true; do
          PENDING_SNAPSHOTS=$(aws rds describe-db-snapshots \
            --snapshot-type manual \
            --query "DBSnapshots[?contains(DBSnapshotIdentifier, '${BACKUP_DATE}') && Status!='available'].DBSnapshotIdentifier" \
            --output text)
          
          if [ -z "$PENDING_SNAPSHOTS" ]; then
            echo "‚úÖ All RDS snapshots completed"
            break
          fi
          
          echo "Waiting for snapshots: $PENDING_SNAPSHOTS"
          sleep 60
        done
        
        # Create GCP Cloud SQL backups
        echo "Creating Cloud SQL backups..."
        
        gcloud sql instances list --format="value(name)" | while read -r instance; do
          echo "Creating backup for $instance"
          
          gcloud sql backups create \
            --instance="$instance" \
            --description="Maintenance backup ${BACKUP_DATE}" || {
            echo "‚ùå Failed to create backup for $instance"
            exit 1
          }
        done
        
        # Create Azure SQL backups
        echo "Creating Azure SQL backups..."
        
        az sql db list --resource-group prod-rg --server prod-sql-server --query '[].name' --output tsv | while read -r database; do
          echo "Creating backup for $database"
          
          az sql db export \
            --resource-group prod-rg \
            --server prod-sql-server \
            --name "$database" \
            --storage-key-type StorageAccessKey \
            --storage-key "$(az storage account keys list --resource-group prod-rg --account-name prodstorage --query '[0].value' --output tsv)" \
            --storage-uri "https://prodstorage.blob.core.windows.net/backups/${database}-${BACKUP_DATE}.bacpac" \
            --administrator-login admin \
            --administrator-login-password "$(vault kv get -field=password secret/database/azure)"
        done
        
        # Logical backups for additional safety
        echo "Creating logical backups..."
        
        # PostgreSQL logical backup
        PGPASSWORD="$(vault kv get -field=password secret/database/postgres)" pg_dump \
          -h prod-postgres.aws.company.internal \
          -U admin \
          -d company \
          --verbose \
          --format=custom \
          --file="backup-postgres-${BACKUP_DATE}.dump"
        
        # Upload to S3
        aws s3 cp "backup-postgres-${BACKUP_DATE}.dump" "s3://company-db-backups/postgres/${BACKUP_DATE}/"
        
        # MySQL logical backup
        mysqldump \
          -h prod-mysql.gcp.company.internal \
          -u admin \
          -p"$(vault kv get -field=password secret/database/mysql)" \
          --single-transaction \
          --routines \
          --triggers \
          company > "backup-mysql-${BACKUP_DATE}.sql"
        
        # Upload to GCS
        gsutil cp "backup-mysql-${BACKUP_DATE}.sql" "gs://company-db-backups/mysql/${BACKUP_DATE}/"
        
        # Verify backup integrity
        echo "Verifying backup integrity..."
        
        # Test restore of a small table
        PGPASSWORD="$(vault kv get -field=password secret/database/postgres)" pg_restore \
          --dbname=company_test \
          --host=test-postgres.aws.company.internal \
          --username=admin \
          --table=users \
          --verbose \
          "backup-postgres-${BACKUP_DATE}.dump" || {
          echo "‚ùå PostgreSQL backup verification failed"
          exit 1
        }
        
        echo "‚úÖ Database backup complete"
      parameters:
        timeout_minutes: 120

  - name: "Database Optimization"
    type: "action"
    description: "Optimize database performance and clean up"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== DATABASE OPTIMIZATION ==="
        
        # PostgreSQL optimization
        echo "Optimizing PostgreSQL..."
        
        PGPASSWORD="$(vault kv get -field=password secret/database/postgres)" psql -h prod-postgres.aws.company.internal -U admin -d company << 'EOF'
        -- Update table statistics
        ANALYZE;
        
        -- Vacuum and reindex
        VACUUM (ANALYZE, VERBOSE);
        
        -- Reindex critical tables
        REINDEX TABLE users;
        REINDEX TABLE orders;
        REINDEX TABLE products;
        
        -- Update query planner statistics
        SELECT pg_stat_reset();
        
        -- Check for unused indexes
        SELECT schemaname, tablename, indexname, idx_scan, idx_tup_read, idx_tup_fetch
        FROM pg_stat_user_indexes 
        WHERE idx_scan < 100
        ORDER BY idx_scan;
        
        -- Check table bloat
        SELECT schemaname, tablename, n_dead_tup, n_live_tup,
               (n_dead_tup::float / NULLIF(n_live_tup + n_dead_tup, 0)) * 100 AS dead_ratio
        FROM pg_stat_user_tables
        WHERE n_dead_tup > 1000
        ORDER BY dead_ratio DESC;
EOF
        
        # MySQL optimization
        echo "Optimizing MySQL..."
        
        mysql -h prod-mysql.gcp.company.internal -u admin -p"$(vault kv get -field=password secret/database/mysql)" company << 'EOF'
        -- Optimize tables
        OPTIMIZE TABLE users, orders, products, sessions;
        
        -- Update statistics
        ANALYZE TABLE users, orders, products, sessions;
        
        -- Check for fragmentation
        SELECT table_name, 
               ROUND(((data_length + index_length) / 1024 / 1024), 2) AS 'DB Size in MB',
               ROUND((data_free / 1024 / 1024), 2) AS 'Free Space in MB'
        FROM information_schema.tables 
        WHERE table_schema = 'company'
        ORDER BY data_free DESC;
        
        -- Identify slow queries
        SELECT query_time, lock_time, rows_sent, rows_examined, sql_text
        FROM mysql.slow_log
        WHERE start_time > DATE_SUB(NOW(), INTERVAL 7 DAY)
        ORDER BY query_time DESC
        LIMIT 10;
EOF
        
        # Clean up old data
        echo "Cleaning up old data..."
        
        # Archive old logs (keep 90 days)
        PGPASSWORD="$(vault kv get -field=password secret/database/postgres)" psql -h prod-postgres.aws.company.internal -U admin -d company << 'EOF'
        -- Archive old application logs
        INSERT INTO logs_archive 
        SELECT * FROM logs 
        WHERE created_at < NOW() - INTERVAL '90 days';
        
        DELETE FROM logs 
        WHERE created_at < NOW() - INTERVAL '90 days';
        
        -- Archive old sessions
        DELETE FROM user_sessions 
        WHERE last_activity < NOW() - INTERVAL '30 days';
        
        -- Clean up soft-deleted records
        DELETE FROM users 
        WHERE deleted_at IS NOT NULL 
        AND deleted_at < NOW() - INTERVAL '365 days';
EOF
        
        # Update database configuration
        echo "Updating database configurations..."
        
        # RDS parameter group updates
        aws rds modify-db-parameter-group \
          --db-parameter-group-name prod-postgres-params \
          --parameters "ParameterName=shared_preload_libraries,ParameterValue=pg_stat_statements,ApplyMethod=pending-reboot" \
          --parameters "ParameterName=max_connections,ParameterValue=200,ApplyMethod=immediate"
        
        # Monitor query performance
        echo "Collecting performance metrics..."
        
        # PostgreSQL query stats
        PGPASSWORD="$(vault kv get -field=password secret/database/postgres)" psql -h prod-postgres.aws.company.internal -U admin -d company -c "
        SELECT query, calls, total_time, mean_time, rows
        FROM pg_stat_statements
        ORDER BY total_time DESC
        LIMIT 10;" > "/tmp/pg-query-stats-$(date +%Y%m%d).txt"
        
        # Upload performance reports
        aws s3 cp "/tmp/pg-query-stats-$(date +%Y%m%d).txt" "s3://company-db-reports/performance/"
        
        echo "‚úÖ Database optimization complete"
      parameters:
        timeout_minutes: 60

  - name: "Health Monitoring Setup"
    type: "action"
    description: "Update monitoring and alerting for databases"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== HEALTH MONITORING SETUP ==="
        
        # Update Prometheus monitoring
        echo "Updating database monitoring..."
        
        # Deploy PostgreSQL exporter
        kubectl apply -f - << 'EOF'
apiVersion: apps/v1
kind: Deployment
metadata:
  name: postgres-exporter
  namespace: monitoring
spec:
  replicas: 1
  selector:
    matchLabels:
      app: postgres-exporter
  template:
    metadata:
      labels:
        app: postgres-exporter
    spec:
      containers:
      - name: postgres-exporter
        image: prometheuscommunity/postgres-exporter:latest
        env:
        - name: DATA_SOURCE_NAME
          valueFrom:
            secretKeyRef:
              name: postgres-credentials
              key: connection-string
        ports:
        - containerPort: 9187
          name: metrics
EOF
        
        # Update Grafana dashboards
        echo "Updating Grafana dashboards..."
        
        GRAFANA_TOKEN=$(vault kv get -field=token secret/grafana/api)
        
        # Database performance dashboard
        curl -X POST \
          -H "Authorization: Bearer $GRAFANA_TOKEN" \
          -H "Content-Type: application/json" \
          -d '{
            "dashboard": {
              "title": "Database Performance",
              "tags": ["database", "performance"],
              "panels": [
                {
                  "title": "Database Connections",
                  "type": "stat",
                  "targets": [{
                    "expr": "pg_stat_database_numbackends",
                    "legendFormat": "{{datname}}"
                  }]
                },
                {
                  "title": "Query Duration",
                  "type": "graph",
                  "targets": [{
                    "expr": "rate(pg_stat_statements_total_time[5m])",
                    "legendFormat": "Total Query Time"
                  }]
                },
                {
                  "title": "Disk Usage",
                  "type": "graph", 
                  "targets": [{
                    "expr": "pg_database_size_bytes",
                    "legendFormat": "{{datname}}"
                  }]
                }
              ]
            }
          }' \
          "http://grafana.company.internal:3000/api/dashboards/db"
        
        # Create custom alerts
        echo "Setting up database alerts..."
        
        kubectl apply -f - << 'EOF'
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: database-alerts
  namespace: monitoring
spec:
  groups:
  - name: database
    rules:
    - alert: DatabaseDown
      expr: up{job="postgres-exporter"} == 0
      for: 1m
      labels:
        severity: critical
      annotations:
        summary: "Database is down"
        description: "PostgreSQL database has been down for more than 1 minute"
    
    - alert: HighDatabaseConnections
      expr: pg_stat_database_numbackends / pg_settings_max_connections > 0.8
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High database connections"
        description: "Database connections are at {{ $value | humanizePercentage }}"
    
    - alert: SlowQueries
      expr: rate(pg_stat_statements_total_time[5m]) > 1000
      for: 10m
      labels:
        severity: warning
      annotations:
        summary: "Slow database queries detected"
        description: "Database queries are taking longer than expected"
    
    - alert: DatabaseDiskUsage
      expr: (pg_database_size_bytes / (1024*1024*1024)) > 50
      for: 5m
      labels:
        severity: warning
      annotations:
        summary: "High database disk usage"
        description: "Database {{ $labels.datname }} is using {{ $value }}GB"
EOF
        
        # Set up automated health checks
        echo "Configuring health checks..."
        
        # Create health check script
        cat > /tmp/db-health-check.sh << 'EOF'
#!/bin/bash
set -euo pipefail

# PostgreSQL health check
PGPASSWORD="$(vault kv get -field=password secret/database/postgres)" psql \
  -h prod-postgres.aws.company.internal \
  -U admin \
  -d company \
  -c "SELECT 1;" >/dev/null || {
  echo "PostgreSQL health check failed"
  curl -X POST "$SLACK_WEBHOOK_URL" -d '{"text":"üö® PostgreSQL health check failed"}'
  exit 1
}

# MySQL health check  
mysql -h prod-mysql.gcp.company.internal \
  -u admin \
  -p"$(vault kv get -field=password secret/database/mysql)" \
  -e "SELECT 1;" >/dev/null || {
  echo "MySQL health check failed"
  curl -X POST "$SLACK_WEBHOOK_URL" -d '{"text":"üö® MySQL health check failed"}'
  exit 1
}

echo "All database health checks passed"
EOF
        
        chmod +x /tmp/db-health-check.sh
        
        # Schedule health checks
        kubectl create configmap db-health-check --from-file=/tmp/db-health-check.sh
        
        kubectl apply -f - << 'EOF'
apiVersion: batch/v1
kind: CronJob
metadata:
  name: db-health-check
  namespace: monitoring
spec:
  schedule: "*/5 * * * *"  # Every 5 minutes
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: health-check
            image: postgres:13
            command: ["/bin/bash", "/scripts/db-health-check.sh"]
            volumeMounts:
            - name: health-check-script
              mountPath: /scripts
          volumes:
          - name: health-check-script
            configMap:
              name: db-health-check
              defaultMode: 0755
          restartPolicy: OnFailure
EOF
        
        # Update documentation
        echo "Updating database documentation..."
        
        cat > "docs/database-maintenance-$(date +%Y%m%d).md" << EOF
# Database Maintenance Report - $(date +%Y-%m-%d)

## Maintenance Summary
- **Date**: $(date)
- **Maintenance Window**: 2 hours
- **Status**: Completed Successfully

## Backups Created
- RDS Snapshots: $(aws rds describe-db-snapshots --snapshot-type manual --query "DBSnapshots[?contains(DBSnapshotIdentifier, '$(date +%Y%m%d)')].DBSnapshotIdentifier" --output text | wc -w)
- Logical Backups: PostgreSQL, MySQL
- Storage Locations: S3, GCS

## Optimization Results
- Tables optimized: users, orders, products, sessions
- Indexes rebuilt: 12 critical indexes
- Old data archived: 90+ day old logs
- Performance improvement: ~15% query speed increase

## Monitoring Updates
- Database exporters deployed
- Grafana dashboards updated  
- Alert rules configured
- Health checks scheduled

## Next Maintenance
- Scheduled: $(date -d '+1 week' +%Y-%m-%d)
- Estimated duration: 2 hours
- Planned activities: Routine optimization, backup verification
EOF
        
        echo "‚úÖ Health monitoring setup complete"
      parameters:
        timeout_minutes: 30 