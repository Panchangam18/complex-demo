goal: Automatically scale RDS connection pools when application traffic increases
  to prevent connection exhaustion
steps:
- name: Get RDS connection metrics
  type: integration
  integration: aws
  method: cloudwatch.GetMetricStatistics
  parameters:
    Namespace: AWS/RDS
    MetricName: DatabaseConnections
    Dimensions:
    - Name: DBInstanceIdentifier
      Value: ${RDS_INSTANCE_ID}
    StartTime: ${FIFTEEN_MINUTES_AGO}
    EndTime: ${NOW}
    Period: 300
    Statistics:
    - Average
    - Maximum
- name: Check ALB request metrics
  type: integration
  integration: aws
  method: cloudwatch.GetMetricStatistics
  parameters:
    Namespace: AWS/ApplicationELB
    MetricName: RequestCount
    Dimensions:
    - Name: LoadBalancer
      Value: ${ALB_NAME}
    StartTime: ${FIFTEEN_MINUTES_AGO}
    EndTime: ${NOW}
    Period: 300
    Statistics:
    - Sum
- name: List pods by connection usage
  type: cli
  command: kubectl exec -n ${NAMESPACE} deployment/${DEPLOYMENT} -- sh -c 'netstat
    -an | grep :5432 | grep ESTABLISHED | wc -l'
- name: Get HikariCP pool metrics
  type: cli
  command: kubectl exec -n ${NAMESPACE} ${POD_NAME} -- curl -s localhost:8080/actuator/metrics/hikaricp.connections.active
- name: Analyze connection patterns
  type: prompt
  prompt: Calculate optimal pool size based on current usage, traffic patterns, and
    RDS max_connections limit.
- name: Get current ConfigMap
  type: integration
  integration: kubernetes
  method: CoreV1Api.read_namespaced_config_map
  parameters:
    name: ${APP_CONFIG}
    namespace: ${NAMESPACE}
- name: Update ConfigMap with new pool size
  type: integration
  integration: kubernetes
  method: CoreV1Api.patch_namespaced_config_map
  parameters:
    name: ${APP_CONFIG}
    namespace: ${NAMESPACE}
    body:
      data:
        hikari.maximum-pool-size: ${NEW_POOL_SIZE}
        hikari.connection-timeout: '30000'
- name: Trigger rolling restart
  type: cli
  command: kubectl rollout restart deployment/${DEPLOYMENT} -n ${NAMESPACE}
- name: Monitor rollout status
  type: cli
  command: kubectl rollout status deployment/${DEPLOYMENT} -n ${NAMESPACE} --timeout=300s
- name: Check RDS CPU usage
  type: integration
  integration: aws
  method: cloudwatch.GetMetricStatistics
  parameters:
    Namespace: AWS/RDS
    MetricName: CPUUtilization
    Dimensions:
    - Name: DBInstanceIdentifier
      Value: ${RDS_INSTANCE_ID}
    StartTime: ${FIVE_MINUTES_AGO}
    EndTime: ${NOW}
    Period: 60
    Statistics:
    - Average
- name: Monitor application errors
  type: integration
  integration: datadog
  method: MetricsApi.query_timeseries_data
  parameters:
    body:
      data:
        type: timeseries_request
        attributes:
          formulas:
          - formula: query1
          queries:
          - name: query1
            data_source: metrics
            query: sum:app.database.connection.errors{service:${SERVICE_NAME}}.as_rate()
          from: now-5m
          to: now
- name: Evaluate scaling success
  type: prompt
  prompt: Check if RDS CPU > 80% or connection errors persist. If so, prepare to scale
    back or create capacity planning ticket.
- name: Scale back if needed
  type: integration
  integration: kubernetes
  method: CoreV1Api.patch_namespaced_config_map
  parameters:
    name: ${APP_CONFIG}
    namespace: ${NAMESPACE}
    body:
      data:
        hikari.maximum-pool-size: ${PREVIOUS_POOL_SIZE}

