goal: "Provision new infrastructure across multicloud environment with full validation and rollback capabilities"
generate_pr: true

triggers:
  - display_name: "Infrastructure Change Request"
    description: "Triggered when infrastructure changes are requested via ServiceNow or manual execution"
    provider: "webhook"
    config:
      webhook_url: "https://api.company.com/webhooks/infrastructure"
      secret_token: "INFRA_WEBHOOK_SECRET"
    labels:
      priority: "high"
      team: "platform-engineering"
      compliance: "required"

steps:
  - name: "Pre-flight Validation"
    type: "action"
    description: "Validate prerequisites, permissions, and safety checks before provisioning"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== PRE-FLIGHT VALIDATION ==="
        
        # Check Terraform Cloud access
        terraform login -json || { echo "‚ùå Terraform Cloud auth failed"; exit 1; }
        
        # Validate AWS access across all accounts
        for account in prod-landing-zone nonprod-landing-zone shared-services; do
          aws sts get-caller-identity --profile $account || { echo "‚ùå AWS access failed for $account"; exit 1; }
        done
        
        # Validate GCP access across all projects
        for project in prod-main nonprod-main shared-services-main; do
          gcloud config set project $project
          gcloud auth application-default print-access-token >/dev/null || { echo "‚ùå GCP access failed for $project"; exit 1; }
        done
        
        # Validate Azure access
        az account show >/dev/null || { echo "‚ùå Azure authentication failed"; exit 1; }
        
        # Check Vault connectivity
        vault status || { echo "‚ùå Vault connectivity failed"; exit 1; }
        
        # Validate Consul connectivity across all datacenters
        for dc in aws-us-east-1 aws-us-west-2 gcp-us-central1 azure-eastus; do
          consul members -datacenter=$dc || { echo "‚ùå Consul connectivity failed for $dc"; exit 1; }
        done
        
        # Check for maintenance windows
        if [ "$(date +%u)" -eq 1 ] && [ "$(date +%H)" -lt 10 ]; then
          echo "‚ö†Ô∏è  Monday morning maintenance window - proceed with caution"
        fi
        
        # Validate CircleCI pipeline status
        circleci-cli api "/api/v2/project/github/company/infrastructure/pipeline" | jq -r '.state' | grep -q "success" || {
          echo "‚ùå Latest infrastructure pipeline failed - investigate before proceeding"
          exit 1
        }
        
        echo "‚úÖ Pre-flight validation complete"
      parameters:
        timeout_minutes: 10
        retry_count: 2
        
  - name: "Terraform State Lock Check"
    type: "action"
    description: "Ensure no concurrent Terraform operations are running"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== TERRAFORM STATE LOCK CHECK ==="
        
        # Check for existing state locks across all environments
        for env in prod nonprod shared; do
          for cloud in aws gcp azure; do
            workspace="${env}-${cloud}"
            echo "Checking workspace: $workspace"
            
            # Use Terraform Cloud API to check for locks
            TFC_TOKEN=$(vault kv get -field=token secret/terraform-cloud/api)
            
            LOCK_STATUS=$(curl -s \
              --header "Authorization: Bearer $TFC_TOKEN" \
              --header "Content-Type: application/vnd.api+json" \
              "https://app.terraform.io/api/v2/workspaces/$workspace/current-state-version" \
              | jq -r '.data.attributes.locked // false')
            
            if [ "$LOCK_STATUS" = "true" ]; then
              echo "‚ùå Workspace $workspace is locked - waiting for release..."
              
              # Wait up to 30 minutes for lock release
              timeout=30
              while [ $timeout -gt 0 ]; do
                sleep 60
                LOCK_STATUS=$(curl -s \
                  --header "Authorization: Bearer $TFC_TOKEN" \
                  --header "Content-Type: application/vnd.api+json" \
                  "https://app.terraform.io/api/v2/workspaces/$workspace/current-state-version" \
                  | jq -r '.data.attributes.locked // false')
                
                if [ "$LOCK_STATUS" = "false" ]; then
                  echo "‚úÖ Lock released for $workspace"
                  break
                fi
                
                timeout=$((timeout - 1))
                echo "‚è≥ Waiting for lock release... ${timeout} minutes remaining"
              done
              
              if [ $timeout -eq 0 ]; then
                echo "‚ùå Timeout waiting for lock release on $workspace"
                exit 1
              fi
            else
              echo "‚úÖ No lock on $workspace"
            fi
          done
        done
        
        echo "‚úÖ All state locks cleared"
      parameters:
        timeout_minutes: 35
        
  - name: "Security Compliance Scan"
    type: "action"
    description: "Run security and compliance scans on infrastructure code"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== SECURITY COMPLIANCE SCAN ==="
        
        # Run tflint across all modules
        echo "Running tflint validation..."
        find modules/ -name "*.tf" -exec dirname {} \; | sort -u | while read -r dir; do
          echo "Scanning $dir"
          cd "$dir"
          tflint --config="$WORKSPACE/.tflint.hcl" || { echo "‚ùå tflint failed for $dir"; exit 1; }
          cd - >/dev/null
        done
        
        # Run Checkov security scans
        echo "Running Checkov security scan..."
        checkov -d . --framework terraform \
          --check CKV_AWS_20,CKV_AWS_21,CKV_AWS_23,CKV_AWS_24,CKV_AWS_25 \
          --check CKV_GCP_1,CKV_GCP_2,CKV_GCP_3,CKV_GCP_6,CKV_GCP_7 \
          --check CKV_AZURE_1,CKV_AZURE_2,CKV_AZURE_3,CKV_AZURE_4 \
          --output json --output-file checkov-results.json || {
          echo "‚ùå Checkov security scan failed"
          exit 1
        }
        
        # Run Terraform validate
        echo "Running terraform validate..."
        for env_dir in envs/*/; do
          echo "Validating $env_dir"
          cd "$env_dir"
          terraform init -backend=false
          terraform validate || { echo "‚ùå Terraform validate failed for $env_dir"; exit 1; }
          cd - >/dev/null
        done
        
        # Run custom compliance checks
        echo "Running custom compliance checks..."
        
        # Check for required tags
        grep -r "required_tags" modules/ || { echo "‚ùå Missing required tags configuration"; exit 1; }
        
        # Check for encryption settings
        grep -r "encrypt.*=.*true" modules/ || { echo "‚ùå Missing encryption configuration"; exit 1; }
        
        # Check for backup configurations
        grep -r "backup_retention_days" modules/ || { echo "‚ùå Missing backup retention configuration"; exit 1; }
        
        # Validate network security groups
        python3 scripts/validate-security-groups.py || { echo "‚ùå Security group validation failed"; exit 1; }
        
        echo "‚úÖ Security compliance scan complete"
      parameters:
        timeout_minutes: 15
        
  - name: "Cross-Cloud Network Validation"
    type: "action"
    description: "Validate network connectivity and addressing across all clouds"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== CROSS-CLOUD NETWORK VALIDATION ==="
        
        # Validate CIDR allocation
        echo "Validating CIDR allocation..."
        python3 scripts/validate-cidr-allocation.py || { echo "‚ùå CIDR validation failed"; exit 1; }
        
        # Test VPN connectivity
        echo "Testing VPN connectivity..."
        
        # AWS Transit Gateway status
        aws ec2 describe-transit-gateways --filters "Name=state,Values=available" --query 'TransitGateways[*].[TransitGatewayId,State]' --output table
        
        # GCP VPN tunnel status
        gcloud compute vpn-tunnels list --filter="status:ESTABLISHED" --format="table(name,status,peerIp)"
        
        # Azure VPN gateway status
        az network vnet-gateway list --query '[*].[name,provisioningState]' --output table
        
        # Test cross-cloud connectivity
        echo "Testing cross-cloud connectivity..."
        
        # Test AWS to GCP connectivity
        aws ec2 describe-instances --filters "Name=tag:Name,Values=connectivity-test" --query 'Reservations[*].Instances[*].[InstanceId,PrivateIpAddress,State.Name]' --output table
        
        # Run connectivity tests from test instances
        TEST_INSTANCES=(
          "aws:i-0123456789abcdef0:10.0.1.10"
          "gcp:connectivity-test-gcp:10.1.1.10"
          "azure:connectivity-test-azure:10.2.1.10"
        )
        
        for instance in "${TEST_INSTANCES[@]}"; do
          IFS=':' read -r cloud instance_id ip <<< "$instance"
          echo "Testing connectivity from $cloud instance $instance_id ($ip)"
          
          case $cloud in
            aws)
              aws ssm send-command \
                --instance-ids "$instance_id" \
                --document-name "AWS-RunShellScript" \
                --parameters 'commands=["ping -c 3 10.1.1.10", "ping -c 3 10.2.1.10"]' \
                --output table
              ;;
            gcp)
              gcloud compute ssh "$instance_id" --zone=us-central1-a --command="ping -c 3 10.0.1.10 && ping -c 3 10.2.1.10"
              ;;
            azure)
              az vm run-command invoke \
                --resource-group connectivity-test \
                --name "$instance_id" \
                --command-id RunShellScript \
                --scripts "ping -c 3 10.0.1.10 && ping -c 3 10.1.1.10"
              ;;
          esac
        done
        
        echo "‚úÖ Cross-cloud network validation complete"
      parameters:
        timeout_minutes: 20
        
  - name: "Terraform Plan Generation"
    type: "action"
    description: "Generate and validate Terraform execution plans for all environments"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== TERRAFORM PLAN GENERATION ==="
        
        # Generate plans for all environments
        ENVIRONMENTS=("prod" "nonprod" "shared")
        CLOUDS=("aws" "gcp" "azure")
        
        for env in "${ENVIRONMENTS[@]}"; do
          for cloud in "${CLOUDS[@]}"; do
            workspace="${env}-${cloud}"
            env_dir="envs/${env}/${cloud}"
            
            echo "Generating plan for $workspace ($env_dir)"
            
            cd "$env_dir"
            
            # Initialize Terraform
            terraform init -upgrade
            
            # Select workspace
            terraform workspace select "$workspace" || terraform workspace new "$workspace"
            
            # Generate plan
            terraform plan \
              -var-file="../../../vars/${env}.tfvars" \
              -var-file="../../../vars/${cloud}.tfvars" \
              -out="${workspace}.tfplan" \
              -detailed-exitcode || {
              
              EXIT_CODE=$?
              if [ $EXIT_CODE -eq 1 ]; then
                echo "‚ùå Terraform plan failed for $workspace"
                exit 1
              elif [ $EXIT_CODE -eq 2 ]; then
                echo "üìã Changes detected for $workspace"
                
                # Show plan summary
                terraform show -json "${workspace}.tfplan" | jq '.resource_changes | group_by(.change.actions[0]) | map({action: .[0].change.actions[0], count: length})'
                
                # Save plan summary
                terraform show "${workspace}.tfplan" > "${workspace}-plan-summary.txt"
              else
                echo "‚úÖ No changes for $workspace"
              fi
            }
            
            cd - >/dev/null
          done
        done
        
        # Aggregate all plan summaries
        echo "=== PLAN SUMMARY ==="
        find envs/ -name "*-plan-summary.txt" -exec echo "--- {} ---" \; -exec cat {} \; -exec echo "" \;
        
        echo "‚úÖ Terraform plan generation complete"
      parameters:
        timeout_minutes: 30
        
  - name: "Change Approval Gate"
    type: "action"
    description: "Require manual approval for infrastructure changes"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== CHANGE APPROVAL GATE ==="
        
        # Check if there are any changes to apply
        if ! find envs/ -name "*.tfplan" -exec terraform show -json {} \; | jq -e '.resource_changes[] | select(.change.actions[] | contains("create", "update", "delete"))' >/dev/null 2>&1; then
          echo "‚úÖ No changes detected - skipping approval gate"
          exit 0
        fi
        
        # Generate change request
        CHANGE_REQUEST_ID=$(date +%Y%m%d%H%M%S)
        
        echo "üìã Change Request ID: $CHANGE_REQUEST_ID"
        echo "üîç Review required for infrastructure changes"
        
        # Create change request in ServiceNow
        curl -X POST "https://company.service-now.com/api/now/table/change_request" \
          -H "Authorization: Bearer $(vault kv get -field=token secret/servicenow/api)" \
          -H "Content-Type: application/json" \
          -d '{
            "short_description": "Infrastructure provisioning - Change Request '"$CHANGE_REQUEST_ID"'",
            "description": "Automated infrastructure provisioning request. See attached Terraform plans for details.",
            "category": "Infrastructure",
            "priority": "3",
            "risk": "Medium",
            "type": "Standard"
          }'
        
        # Send Slack notification
        curl -X POST "$SLACK_WEBHOOK_URL" \
          -H "Content-Type: application/json" \
          -d '{
            "channel": "#platform-engineering",
            "text": "üö® Infrastructure Change Approval Required",
            "attachments": [{
              "color": "warning",
              "fields": [{
                "title": "Change Request ID",
                "value": "'"$CHANGE_REQUEST_ID"'",
                "short": true
              }, {
                "title": "Status",
                "value": "Pending Approval",
                "short": true
              }]
            }]
          }'
        
        # Wait for approval (this would be replaced with actual approval system integration)
        echo "‚è≥ Waiting for approval..."
        echo "To approve this change, run: approve-change $CHANGE_REQUEST_ID"
        
        # In a real implementation, this would wait for approval via API
        # For now, we'll simulate a manual approval step
        read -p "Press Enter when change has been approved..."
        
        echo "‚úÖ Change approved - proceeding with deployment"
      parameters:
        timeout_minutes: 60
        manual_approval: true
        
  - name: "Terraform Apply"
    type: "action"
    description: "Apply Terraform changes across all environments"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== TERRAFORM APPLY ==="
        
        # Apply changes in dependency order
        APPLY_ORDER=(
          "shared:aws"
          "shared:gcp"
          "shared:azure"
          "nonprod:aws"
          "nonprod:gcp"
          "nonprod:azure"
          "prod:aws"
          "prod:gcp"
          "prod:azure"
        )
        
        for env_cloud in "${APPLY_ORDER[@]}"; do
          IFS=':' read -r env cloud <<< "$env_cloud"
          workspace="${env}-${cloud}"
          env_dir="envs/${env}/${cloud}"
          
          echo "Applying changes for $workspace ($env_dir)"
          
          cd "$env_dir"
          
          # Check if plan exists
          if [ ! -f "${workspace}.tfplan" ]; then
            echo "‚ö†Ô∏è  No plan found for $workspace - skipping"
            cd - >/dev/null
            continue
          fi
          
          # Apply the plan
          terraform apply "${workspace}.tfplan" || {
            echo "‚ùå Terraform apply failed for $workspace"
            
            # Attempt rollback if critical infrastructure
            if [[ "$env" == "prod" ]]; then
              echo "üîÑ Attempting rollback for production environment"
              terraform plan -destroy -out="${workspace}-rollback.tfplan"
              
              # This would trigger a separate approval process for rollback
              echo "‚ö†Ô∏è  Rollback plan generated - manual intervention required"
            fi
            
            exit 1
          }
          
          # Clean up plan file
          rm -f "${workspace}.tfplan"
          
          cd - >/dev/null
          
          echo "‚úÖ Successfully applied changes for $workspace"
          
          # Wait between environments to avoid rate limits
          sleep 30
        done
        
        echo "‚úÖ Terraform apply complete"
      parameters:
        timeout_minutes: 60
        
  - name: "Post-Deployment Validation"
    type: "action"
    description: "Validate infrastructure after deployment"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== POST-DEPLOYMENT VALIDATION ==="
        
        # Wait for resources to stabilize
        echo "‚è≥ Waiting for resources to stabilize..."
        sleep 120
        
        # Validate AWS resources
        echo "Validating AWS resources..."
        
        # Check EC2 instances
        aws ec2 describe-instances --filters "Name=instance-state-name,Values=running" --query 'Reservations[*].Instances[*].[InstanceId,State.Name,Tags[?Key==`Name`].Value|[0]]' --output table
        
        # Check EKS clusters
        aws eks describe-cluster --name prod-cluster --query 'cluster.status' --output text | grep -q "ACTIVE" || { echo "‚ùå EKS cluster not active"; exit 1; }
        
        # Check RDS instances
        aws rds describe-db-instances --query 'DBInstances[*].[DBInstanceIdentifier,DBInstanceStatus]' --output table
        
        # Validate GCP resources
        echo "Validating GCP resources..."
        
        # Check GKE clusters
        gcloud container clusters describe prod-cluster --zone=us-central1-a --format="value(status)" | grep -q "RUNNING" || { echo "‚ùå GKE cluster not running"; exit 1; }
        
        # Check Compute instances
        gcloud compute instances list --filter="status:RUNNING" --format="table(name,status,zone)"
        
        # Validate Azure resources
        echo "Validating Azure resources..."
        
        # Check AKS clusters
        az aks show --resource-group prod-rg --name prod-cluster --query 'provisioningState' --output tsv | grep -q "Succeeded" || { echo "‚ùå AKS cluster not ready"; exit 1; }
        
        # Check VMs
        az vm list --query '[*].[name,provisioningState]' --output table
        
        # Validate cross-cloud connectivity
        echo "Validating cross-cloud connectivity..."
        
        # Test Consul connectivity
        consul members -wan | grep -q "alive" || { echo "‚ùå Consul WAN federation issues"; exit 1; }
        
        # Test Vault connectivity
        vault status | grep -q "Sealed.*false" || { echo "‚ùå Vault not accessible"; exit 1; }
        
        # Validate monitoring stack
        echo "Validating monitoring stack..."
        
        # Check Prometheus targets
        curl -s "http://prometheus.company.internal:9090/api/v1/targets" | jq -r '.data.activeTargets[] | select(.health != "up") | .labels.instance' | while read -r instance; do
          echo "‚ö†Ô∏è  Prometheus target down: $instance"
        done
        
        # Check Grafana dashboards
        curl -s -H "Authorization: Bearer $(vault kv get -field=token secret/grafana/api)" \
          "http://grafana.company.internal:3000/api/dashboards/tags/infrastructure" | jq '.[] | .title' || {
          echo "‚ùå Grafana dashboards not accessible"
          exit 1
        }
        
        echo "‚úÖ Post-deployment validation complete"
      parameters:
        timeout_minutes: 20
        
  - name: "Update Configuration Management"
    type: "action"
    description: "Update Ansible inventories and Puppet classifications"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== UPDATE CONFIGURATION MANAGEMENT ==="
        
        # Update Ansible inventories from Terraform state
        echo "Updating Ansible inventories..."
        
        # Generate inventories for each environment
        for env in prod nonprod shared; do
          echo "Generating inventory for $env"
          
          # Use terraform-inventory to generate dynamic inventory
          terraform-inventory -inventory envs/${env}/aws > ansible/inventories/${env}-aws.json
          terraform-inventory -inventory envs/${env}/gcp > ansible/inventories/${env}-gcp.json
          terraform-inventory -inventory envs/${env}/azure > ansible/inventories/${env}-azure.json
          
          # Merge inventories
          python3 scripts/merge-inventories.py \
            ansible/inventories/${env}-aws.json \
            ansible/inventories/${env}-gcp.json \
            ansible/inventories/${env}-azure.json \
            > ansible/inventories/${env}-merged.json
        done
        
        # Update Puppet Hiera data
        echo "Updating Puppet Hiera data..."
        
        # Generate Hiera data from Terraform outputs
        for env in prod nonprod shared; do
          for cloud in aws gcp azure; do
            cd "envs/${env}/${cloud}"
            
            # Extract Terraform outputs
            terraform output -json > "../../../puppet/data/terraform-${env}-${cloud}.json"
            
            cd - >/dev/null
          done
          
          # Generate environment-specific Hiera
          python3 scripts/generate-hiera.py \
            --environment "$env" \
            --output "puppet/data/environment/${env}.yaml"
        done
        
        # Trigger Ansible Tower job to update inventories
        echo "Triggering Ansible Tower inventory sync..."
        
        TOWER_TOKEN=$(vault kv get -field=token secret/ansible-tower/api)
        
        for env in prod nonprod shared; do
          JOB_ID=$(curl -s -X POST \
            -H "Authorization: Bearer $TOWER_TOKEN" \
            -H "Content-Type: application/json" \
            "https://tower.company.internal/api/v2/inventories/${env}-inventory/update_inventory_sources/" \
            | jq -r '.inventory_updates[0].id')
          
          echo "Started inventory sync job $JOB_ID for $env"
          
          # Wait for job completion
          while true; do
            STATUS=$(curl -s -H "Authorization: Bearer $TOWER_TOKEN" \
              "https://tower.company.internal/api/v2/inventory_updates/$JOB_ID/" \
              | jq -r '.status')
            
            if [ "$STATUS" = "successful" ]; then
              echo "‚úÖ Inventory sync completed for $env"
              break
            elif [ "$STATUS" = "failed" ]; then
              echo "‚ùå Inventory sync failed for $env"
              exit 1
            fi
            
            sleep 10
          done
        done
        
        # Trigger Puppet classification update
        echo "Triggering Puppet classification update..."
        
        # Update Puppet ENC (External Node Classifier)
        python3 scripts/update-puppet-enc.py \
          --hiera-dir puppet/data/environment \
          --enc-script puppet/enc/terraform-enc.py
        
        # Test Puppet classification
        puppet node classify test-node.company.internal || {
          echo "‚ùå Puppet classification test failed"
          exit 1
        }
        
        echo "‚úÖ Configuration management update complete"
      parameters:
        timeout_minutes: 15
        
  - name: "Service Registration"
    type: "action"
    description: "Register new services with Consul and update service mesh"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== SERVICE REGISTRATION ==="
        
        # Discover new services from Terraform outputs
        echo "Discovering new services..."
        
        NEW_SERVICES=()
        
        for env in prod nonprod shared; do
          for cloud in aws gcp azure; do
            cd "envs/${env}/${cloud}"
            
            # Extract service information from Terraform outputs
            terraform output -json | jq -r '.services.value[]? | @base64' | while read -r service; do
              SERVICE_DATA=$(echo "$service" | base64 -d)
              SERVICE_NAME=$(echo "$SERVICE_DATA" | jq -r '.name')
              SERVICE_ADDRESS=$(echo "$SERVICE_DATA" | jq -r '.address')
              SERVICE_PORT=$(echo "$SERVICE_DATA" | jq -r '.port')
              SERVICE_TAGS=$(echo "$SERVICE_DATA" | jq -r '.tags[]')
              
              NEW_SERVICES+=("$SERVICE_NAME:$SERVICE_ADDRESS:$SERVICE_PORT:$SERVICE_TAGS")
            done
            
            cd - >/dev/null
          done
        done
        
        # Register services with Consul
        echo "Registering services with Consul..."
        
        for service_info in "${NEW_SERVICES[@]}"; do
          IFS=':' read -r name address port tags <<< "$service_info"
          
          echo "Registering service: $name at $address:$port"
          
          # Create service definition
          cat > "/tmp/service-${name}.json" << EOF
{
  "ID": "${name}-$(date +%s)",
  "Name": "$name",
  "Tags": [$(echo "$tags" | sed 's/,/","/g' | sed 's/^/"/;s/$/"/')]
  "Address": "$address",
  "Port": $port,
  "Check": {
    "HTTP": "http://$address:$port/health",
    "Interval": "10s"
  }
}
EOF
          
          # Register with Consul
          consul services register "/tmp/service-${name}.json" || {
            echo "‚ùå Failed to register service $name"
            exit 1
          }
          
          rm -f "/tmp/service-${name}.json"
        done
        
        # Update Consul Connect intentions
        echo "Updating Consul Connect intentions..."
        
        # Apply service mesh policies
        kubectl apply -f consul/service-mesh-policies.yaml
        
        # Verify service registration
        echo "Verifying service registration..."
        
        for service_info in "${NEW_SERVICES[@]}"; do
          IFS=':' read -r name address port tags <<< "$service_info"
          
          # Check service is registered
          consul catalog services | grep -q "$name" || {
            echo "‚ùå Service $name not found in Consul catalog"
            exit 1
          }
          
          # Check service health
          consul health service "$name" | jq -r '.[] | select(.Checks[].Status != "passing") | .Service.ID' | while read -r unhealthy; do
            echo "‚ö†Ô∏è  Service instance $unhealthy is unhealthy"
          done
        done
        
        echo "‚úÖ Service registration complete"
      parameters:
        timeout_minutes: 10
        
  - name: "Monitoring Integration"
    type: "action"
    description: "Update monitoring configuration for new infrastructure"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== MONITORING INTEGRATION ==="
        
        # Update Prometheus configuration
        echo "Updating Prometheus configuration..."
        
        # Generate Prometheus targets from Terraform outputs
        for env in prod nonprod shared; do
          for cloud in aws gcp azure; do
            cd "envs/${env}/${cloud}"
            
            # Extract monitoring targets
            terraform output -json | jq -r '.monitoring_targets.value[]? | @base64' | while read -r target; do
              TARGET_DATA=$(echo "$target" | base64 -d)
              echo "$TARGET_DATA" >> "../../../monitoring/prometheus/targets/${env}-${cloud}.json"
            done
            
            cd - >/dev/null
          done
        done
        
        # Update Prometheus ConfigMap
        kubectl create configmap prometheus-config \
          --from-file=monitoring/prometheus/prometheus.yml \
          --dry-run=client -o yaml | kubectl apply -f -
        
        # Reload Prometheus configuration
        curl -X POST "http://prometheus.company.internal:9090/-/reload" || {
          echo "‚ùå Failed to reload Prometheus configuration"
          exit 1
        }
        
        # Update Grafana dashboards
        echo "Updating Grafana dashboards..."
        
        GRAFANA_TOKEN=$(vault kv get -field=token secret/grafana/api)
        
        # Upload infrastructure dashboards
        for dashboard in monitoring/grafana/dashboards/*.json; do
          DASHBOARD_NAME=$(basename "$dashboard" .json)
          
          echo "Uploading dashboard: $DASHBOARD_NAME"
          
          curl -X POST \
            -H "Authorization: Bearer $GRAFANA_TOKEN" \
            -H "Content-Type: application/json" \
            -d @"$dashboard" \
            "http://grafana.company.internal:3000/api/dashboards/db" || {
            echo "‚ùå Failed to upload dashboard $DASHBOARD_NAME"
            exit 1
          }
        done
        
        # Update alerting rules
        echo "Updating alerting rules..."
        
        # Update Prometheus alerting rules
        kubectl create configmap prometheus-alerts \
          --from-file=monitoring/prometheus/alerts/ \
          --dry-run=client -o yaml | kubectl apply -f -
        
        # Update Grafana alert rules
        for alert in monitoring/grafana/alerts/*.json; do
          ALERT_NAME=$(basename "$alert" .json)
          
          echo "Uploading alert rule: $ALERT_NAME"
          
          curl -X POST \
            -H "Authorization: Bearer $GRAFANA_TOKEN" \
            -H "Content-Type: application/json" \
            -d @"$alert" \
            "http://grafana.company.internal:3000/api/alert-rules" || {
            echo "‚ùå Failed to upload alert rule $ALERT_NAME"
            exit 1
          }
        done
        
        # Update Datadog monitors
        echo "Updating Datadog monitors..."
        
        DD_API_KEY=$(vault kv get -field=api_key secret/datadog/api)
        DD_APP_KEY=$(vault kv get -field=app_key secret/datadog/api)
        
        for monitor in monitoring/datadog/monitors/*.json; do
          MONITOR_NAME=$(basename "$monitor" .json)
          
          echo "Creating Datadog monitor: $MONITOR_NAME"
          
          curl -X POST \
            -H "DD-API-KEY: $DD_API_KEY" \
            -H "DD-APPLICATION-KEY: $DD_APP_KEY" \
            -H "Content-Type: application/json" \
            -d @"$monitor" \
            "https://api.datadoghq.com/api/v1/monitor" || {
            echo "‚ùå Failed to create Datadog monitor $MONITOR_NAME"
            exit 1
          }
        done
        
        # Verify monitoring stack
        echo "Verifying monitoring stack..."
        
        # Check Prometheus targets
        UNHEALTHY_TARGETS=$(curl -s "http://prometheus.company.internal:9090/api/v1/targets" | jq -r '.data.activeTargets[] | select(.health != "up") | .labels.instance')
        
        if [ -n "$UNHEALTHY_TARGETS" ]; then
          echo "‚ö†Ô∏è  Unhealthy Prometheus targets detected:"
          echo "$UNHEALTHY_TARGETS"
        fi
        
        # Check Grafana dashboards
        DASHBOARD_COUNT=$(curl -s -H "Authorization: Bearer $GRAFANA_TOKEN" \
          "http://grafana.company.internal:3000/api/search?tag=infrastructure" | jq length)
        
        echo "‚úÖ $DASHBOARD_COUNT infrastructure dashboards available"
        
        echo "‚úÖ Monitoring integration complete"
      parameters:
        timeout_minutes: 15
        
  - name: "Documentation Update"
    type: "action"
    description: "Update infrastructure documentation and runbooks"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== DOCUMENTATION UPDATE ==="
        
        # Update infrastructure inventory
        echo "Updating infrastructure inventory..."
        
        # Generate infrastructure documentation
        python3 scripts/generate-infrastructure-docs.py \
          --terraform-dir envs/ \
          --output-dir docs/infrastructure/ \
          --format markdown
        
        # Update network diagrams
        echo "Updating network diagrams..."
        
        # Generate network topology diagrams
        python3 scripts/generate-network-diagrams.py \
          --terraform-outputs envs/*/output.json \
          --output-dir docs/diagrams/network/ \
          --format svg
        
        # Update runbooks
        echo "Updating runbooks..."
        
        # Generate service-specific runbooks
        for service in $(consul catalog services | jq -r '.[]'); do
          echo "Generating runbook for service: $service"
          
          # Get service information
          SERVICE_INFO=$(consul catalog service "$service" | jq '.[0]')
          
          # Generate runbook from template
          python3 scripts/generate-runbook.py \
            --service "$service" \
            --service-info "$SERVICE_INFO" \
            --template templates/service-runbook.md.j2 \
            --output "docs/runbooks/services/${service}.md"
        done
        
        # Update architectural decision records (ADRs)
        echo "Updating ADRs..."
        
        # Create ADR for this infrastructure change
        ADR_NUMBER=$(ls docs/adr/ | wc -l | xargs printf "%04d")
        ADR_DATE=$(date +%Y-%m-%d)
        
        cat > "docs/adr/${ADR_NUMBER}-infrastructure-provisioning-${ADR_DATE}.md" << EOF
# ADR-${ADR_NUMBER}: Infrastructure Provisioning $(date +%Y-%m-%d)

## Status
Accepted

## Context
Infrastructure provisioning executed on $(date +%Y-%m-%d) via automated pipeline.

## Decision
Applied infrastructure changes across multicloud environment using Terraform.

## Consequences
- New infrastructure resources provisioned
- Monitoring and alerting updated
- Service mesh configuration updated
- Documentation updated

## Resources Created
$(find envs/ -name "*.tfplan" -exec terraform show -json {} \; | jq -r '.resource_changes[] | select(.change.actions[] | contains("create")) | .address' | sort | uniq)

## Changes Applied
$(find envs/ -name "*-plan-summary.txt" -exec cat {} \;)
EOF
        
        # Update README files
        echo "Updating README files..."
        
        # Update main README
        python3 scripts/update-readme.py \
          --terraform-dir envs/ \
          --readme-template templates/README.md.j2 \
          --output README.md
        
        # Update environment-specific READMEs
        for env in prod nonprod shared; do
          python3 scripts/update-readme.py \
            --terraform-dir "envs/$env" \
            --readme-template templates/environment-README.md.j2 \
            --output "envs/$env/README.md"
        done
        
        # Commit documentation changes
        echo "Committing documentation changes..."
        
        git add docs/ README.md envs/*/README.md
        git commit -m "docs: update infrastructure documentation after provisioning

        - Updated infrastructure inventory
        - Generated network diagrams
        - Updated service runbooks
        - Created ADR for infrastructure changes
        - Updated README files
        
        Change-Id: $(date +%Y%m%d%H%M%S)"
        
        # Push to documentation repository
        git push origin main
        
        echo "‚úÖ Documentation update complete"
      parameters:
        timeout_minutes: 10
        
  - name: "Cleanup and Notification"
    type: "action"
    description: "Clean up temporary files and send completion notifications"
    config:
      command: |
        #!/bin/bash
        set -euo pipefail
        
        echo "=== CLEANUP AND NOTIFICATION ==="
        
        # Clean up temporary files
        echo "Cleaning up temporary files..."
        
        # Remove Terraform plan files
        find envs/ -name "*.tfplan" -delete
        find envs/ -name "*-plan-summary.txt" -delete
        
        # Remove temporary service files
        rm -f /tmp/service-*.json
        
        # Remove temporary monitoring files
        rm -f /tmp/monitoring-*.json
        
        # Generate deployment summary
        echo "Generating deployment summary..."
        
        DEPLOYMENT_ID=$(date +%Y%m%d%H%M%S)
        
        cat > "/tmp/deployment-summary-${DEPLOYMENT_ID}.json" << EOF
{
  "deployment_id": "$DEPLOYMENT_ID",
  "timestamp": "$(date -u +%Y-%m-%dT%H:%M:%SZ)",
  "status": "success",
  "environments": $(echo '["prod", "nonprod", "shared"]' | jq -c),
  "clouds": $(echo '["aws", "gcp", "azure"]' | jq -c),
  "resources_created": $(find envs/ -name "terraform.tfstate" -exec terraform show -json {} \; | jq -s '[.[] | .values.root_module.resources[] | select(.type)] | length'),
  "services_registered": $(consul catalog services | jq length),
  "monitoring_targets": $(curl -s "http://prometheus.company.internal:9090/api/v1/targets" | jq '.data.activeTargets | length')
}
EOF
        
        # Send Slack notification
        echo "Sending Slack notification..."
        
        DEPLOYMENT_SUMMARY=$(cat "/tmp/deployment-summary-${DEPLOYMENT_ID}.json")
        
        curl -X POST "$SLACK_WEBHOOK_URL" \
          -H "Content-Type: application/json" \
          -d '{
            "channel": "#platform-engineering",
            "text": "‚úÖ Infrastructure Provisioning Complete",
            "attachments": [{
              "color": "good",
              "fields": [{
                "title": "Deployment ID",
                "value": "'"$DEPLOYMENT_ID"'",
                "short": true
              }, {
                "title": "Duration",
                "value": "'"$(($(date +%s) - ${WORKFLOW_START_TIME:-$(date +%s)}))"' seconds",
                "short": true
              }, {
                "title": "Resources Created",
                "value": "'"$(echo "$DEPLOYMENT_SUMMARY" | jq -r '.resources_created')"'",
                "short": true
              }, {
                "title": "Services Registered",
                "value": "'"$(echo "$DEPLOYMENT_SUMMARY" | jq -r '.services_registered')"'",
                "short": true
              }]
            }]
          }'
        
        # Send email notification
        echo "Sending email notification..."
        
        cat > "/tmp/email-body-${DEPLOYMENT_ID}.html" << EOF
<!DOCTYPE html>
<html>
<head>
    <title>Infrastructure Provisioning Complete</title>
</head>
<body>
    <h2>Infrastructure Provisioning Complete</h2>
    <p>Deployment ID: <strong>$DEPLOYMENT_ID</strong></p>
    <p>Timestamp: <strong>$(date)</strong></p>
    
    <h3>Summary</h3>
    <ul>
        <li>Environments: prod, nonprod, shared</li>
        <li>Clouds: AWS, GCP, Azure</li>
        <li>Resources Created: $(echo "$DEPLOYMENT_SUMMARY" | jq -r '.resources_created')</li>
        <li>Services Registered: $(echo "$DEPLOYMENT_SUMMARY" | jq -r '.services_registered')</li>
        <li>Monitoring Targets: $(echo "$DEPLOYMENT_SUMMARY" | jq -r '.monitoring_targets')</li>
    </ul>
    
    <h3>Next Steps</h3>
    <ul>
        <li>Review monitoring dashboards</li>
        <li>Verify service connectivity</li>
        <li>Update documentation</li>
        <li>Schedule post-deployment review</li>
    </ul>
    
    <p>For questions or issues, contact the Platform Engineering team.</p>
</body>
</html>
EOF
        
        # Send email via SendGrid
        SENDGRID_API_KEY=$(vault kv get -field=api_key secret/sendgrid/api)
        
        curl -X POST "https://api.sendgrid.com/v3/mail/send" \
          -H "Authorization: Bearer $SENDGRID_API_KEY" \
          -H "Content-Type: application/json" \
          -d '{
            "personalizations": [{
              "to": [{"email": "platform-engineering@company.com"}],
              "subject": "Infrastructure Provisioning Complete - '"$DEPLOYMENT_ID"'"
            }],
            "from": {"email": "automation@company.com"},
            "content": [{
              "type": "text/html",
              "value": "'"$(cat "/tmp/email-body-${DEPLOYMENT_ID}.html" | sed 's/"/\\"/g' | tr -d '\n')"'"
            }]
          }'
        
        # Update deployment tracking
        echo "Updating deployment tracking..."
        
        # Store deployment summary in deployment database
        curl -X POST "https://api.company.internal/deployments" \
          -H "Authorization: Bearer $(vault kv get -field=token secret/internal-api/deployments)" \
          -H "Content-Type: application/json" \
          -d "$DEPLOYMENT_SUMMARY"
        
        # Clean up temporary files
        rm -f "/tmp/deployment-summary-${DEPLOYMENT_ID}.json"
        rm -f "/tmp/email-body-${DEPLOYMENT_ID}.html"
        
        echo "‚úÖ Infrastructure provisioning workflow complete"
        echo "üìä Deployment ID: $DEPLOYMENT_ID"
        echo "üîó Monitoring: http://grafana.company.internal:3000/d/infrastructure"
        echo "üìö Documentation: https://docs.company.internal/infrastructure"
        
      parameters:
        timeout_minutes: 5 