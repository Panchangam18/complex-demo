{
  "goal": "Optimize serverless function cold start performance",
  "steps": [
    {
      "name": "Measure baseline cold starts",
      "type": "integration",
      "integration": "aws",
      "method": "client('lambda').invoke",
      "parameters": {
        "FunctionName": "production-api-handler",
        "InvocationType": "RequestResponse",
        "LogType": "Tail",
        "Payload": "{\"test\": true, \"cold_start_test\": true}"
      },
      "files": []
    },
    {
      "name": "Analyze cold start patterns",
      "type": "cli",
      "command": "aws logs filter-log-events --log-group-name /aws/lambda/production-api-handler --start-time $(date -u -d '1 hour ago' +%s)000 --filter-pattern '[REPORT RequestId=*]' --query 'events[*].[timestamp,message]' --output json | jq -r '.[] | @csv' > /tmp/lambda_reports.csv",
      "files": ["/tmp/lambda_reports.csv"]
    },
    {
      "name": "Implement provisioned concurrency",
      "type": "integration",
      "integration": "aws",
      "method": "client('lambda').put_provisioned_concurrency_config",
      "parameters": {
        "FunctionName": "production-api-handler",
        "ProvisionedConcurrentExecutions": 10,
        "Qualifier": "$LATEST"
      },
      "files": []
    },
    {
      "name": "Optimize function package",
      "type": "cli",
      "command": "cat > /tmp/optimize_lambda.sh << 'EOF'\n#!/bin/bash\n# Remove unnecessary dependencies\nnpm prune --production\n\n# Tree shake and minify\nnpx webpack --mode production --config webpack.lambda.js\n\n# Create layers for shared dependencies\nmkdir -p layers/nodejs/node_modules\ncp -r node_modules/aws-sdk layers/nodejs/node_modules/\ncp -r node_modules/lodash layers/nodejs/node_modules/\n\n# Zip optimized function\nzip -r function.zip dist/ -x \"*.map\" \"*.test.js\"\n\n# Create layer\ncd layers && zip -r ../shared-deps-layer.zip nodejs/\n\n# Check sizes\necho \"Function size: $(du -h ../function.zip | cut -f1)\"\necho \"Layer size: $(du -h ../shared-deps-layer.zip | cut -f1)\"\nEOF\nchmod +x /tmp/optimize_lambda.sh",
      "files": ["/tmp/optimize_lambda.sh"]
    },
    {
      "name": "Configure Lambda SnapStart",
      "type": "integration",
      "integration": "aws",
      "method": "client('lambda').update_function_configuration",
      "parameters": {
        "FunctionName": "production-java-handler",
        "SnapStart": {
          "ApplyOn": "PublishedVersions"
        },
        "Environment": {
          "Variables": {
            "JAVA_TOOL_OPTIONS": "-XX:+TieredCompilation -XX:TieredStopAtLevel=1"
          }
        }
      },
      "files": []
    },
    {
      "name": "Implement connection pooling",
      "type": "cli",
      "command": "cat > /tmp/connection_pool.js << 'EOF'\n// Global connection pool - persists across invocations\nlet dbPool = null;\nlet redisClient = null;\n\nconst initializeConnections = async () => {\n  if (!dbPool) {\n    const { Pool } = require('pg');\n    dbPool = new Pool({\n      connectionString: process.env.DATABASE_URL,\n      max: 2, // Small pool for Lambda\n      idleTimeoutMillis: 30000,\n      connectionTimeoutMillis: 2000,\n    });\n    \n    // Test connection\n    await dbPool.query('SELECT 1');\n  }\n  \n  if (!redisClient) {\n    const Redis = require('ioredis');\n    redisClient = new Redis({\n      host: process.env.REDIS_HOST,\n      port: 6379,\n      maxRetriesPerRequest: 3,\n      enableReadyCheck: false,\n      lazyConnect: true,\n    });\n    \n    await redisClient.connect();\n  }\n  \n  return { dbPool, redisClient };\n};\n\n// Warm up function\nexports.warmUp = async (event) => {\n  if (event.source === 'serverless-plugin-warmup') {\n    await initializeConnections();\n    return { statusCode: 200, body: 'Warm!' };\n  }\n  \n  // Regular execution\n  const { dbPool, redisClient } = await initializeConnections();\n  // ... rest of handler\n};\nEOF",
      "files": ["/tmp/connection_pool.js"]
    },
    {
      "name": "Test cold start improvements",
      "type": "cli",
      "command": "python3 << 'EOF'\nimport boto3\nimport time\nimport json\nimport statistics\n\nlambda_client = boto3.client('lambda')\n\ndef measure_cold_start(function_name, force_cold=False):\n    if force_cold:\n        # Update environment variable to force new container\n        lambda_client.update_function_configuration(\n            FunctionName=function_name,\n            Environment={\n                'Variables': {\n                    'FORCE_COLD_START': str(time.time())\n                }\n            }\n        )\n        time.sleep(5)  # Wait for update\n    \n    start_time = time.time()\n    response = lambda_client.invoke(\n        FunctionName=function_name,\n        InvocationType='RequestResponse',\n        LogType='Tail',\n        Payload=json.dumps({'test': True})\n    )\n    \n    duration = (time.time() - start_time) * 1000\n    \n    # Parse duration from logs\n    import base64\n    log_data = base64.b64decode(response['LogResult']).decode('utf-8')\n    \n    init_duration = None\n    billed_duration = None\n    \n    for line in log_data.split('\\n'):\n        if 'Init Duration:' in line:\n            init_duration = float(line.split('Init Duration:')[1].split('ms')[0].strip())\n        if 'Billed Duration:' in line:\n            billed_duration = float(line.split('Billed Duration:')[1].split('ms')[0].strip())\n    \n    return {\n        'total_duration': duration,\n        'init_duration': init_duration,\n        'billed_duration': billed_duration,\n        'is_cold_start': init_duration is not None\n    }\n\n# Test multiple invocations\nresults = []\nfor i in range(10):\n    force_cold = i % 3 == 0  # Force cold start every 3rd invocation\n    result = measure_cold_start('production-api-handler', force_cold)\n    results.append(result)\n    time.sleep(2)\n\n# Calculate statistics\ncold_starts = [r for r in results if r['is_cold_start']]\nwarm_starts = [r for r in results if not r['is_cold_start']]\n\nstats = {\n    'cold_starts': {\n        'count': len(cold_starts),\n        'avg_init_duration': statistics.mean([r['init_duration'] for r in cold_starts if r['init_duration']]),\n        'avg_total_duration': statistics.mean([r['total_duration'] for r in cold_starts])\n    },\n    'warm_starts': {\n        'count': len(warm_starts),\n        'avg_duration': statistics.mean([r['total_duration'] for r in warm_starts]) if warm_starts else 0\n    },\n    'all_invocations': results\n}\n\nwith open('/tmp/cold_start_analysis.json', 'w') as f:\n    json.dump(stats, f, indent=2)\nEOF",
      "files": ["/tmp/cold_start_analysis.json"]
    },
    {
      "name": "Optimize cold start performance",
      "type": "prompt",
      "prompt": "Analyze the cold start measurements and optimization strategies. Compare init durations before and after optimizations. Recommend additional improvements such as using lighter runtimes, reducing package size, or implementing custom runtimes.",
      "files": ["/tmp/lambda_reports.csv", "/tmp/optimize_lambda.sh", "/tmp/connection_pool.js", "/tmp/cold_start_analysis.json"]
    }
  ]
}